library("dplyr")
library("ggplot2")
library("ggfortify")
view(irir)
library("stats")
view(irir)
view(iris)
install.packages("dplyr")
install.packages("dplyr")
library("dplyr")
library("ggplot2")
library("ggfortify")
library("stats")
view(iris)
View(iris)
data<- select(iris,c(1,4))
for(i in 2:15)
print(i)
data<- select(iris,c(1:4))
wssplot<- fun(data,nc=15,seed=1234){
wss
wssplot<- fun(data,nc=15,seed=1234){
wssplot<- function(data,nc=15,seed=1234){
wss<- (nrow(data)-1)*sum(apply(data,2,var))
for(i in 2:nc){
set.seed(seed)
wss[i]<- sum(kmeans(data,centers = i)$withinss)
}
plot(1:nc,wss,type="b",xlabel="Number of clusters",ylabel="within group sum of sqaures")
wss
}
wssplot(data)
KM <- kmeans(data,centers = 2)
autoplot(KM,data,frame=TRUE)
KM$cluster
KM$centers
KM1<Kmeans(data,centers=3)
KM1<-Kmeans(data,centers=3)
Km <- kmeans(data,centers = 3)
autoplot(Km,data,frame=TRUE)
Km$centers
library("dplyr")
library("randomforest")
library("randomForest")
library("ggplot2")
data<-iris
str(data)
split<- sample.split(data,splitRatio=0.7)
split<- sample.split(data,SplitRatio=0.7)
library("caTools")
split<- sample.split(data,SplitRatio=0.7)
split
train <-subset(data,split==TRUE)
test <-subset(data,split==FALSE)
set.seed(200)
rf_model = randomForest(train[-5],train$Species,ntree=500)
rf_model
pred = predict(rf_model,newdata = test[-5])
conf_mtx = table(test[,5],pred)
conf_mtx
pred_acc = sum(dia(conf_mtx))/sum(conf_mtx)
pred_acc = sum(diag(conf_mtx))/sum(conf_mtx)
pred_acc
plot(conf_mtx)
importance(conf_mtx)
importance(rf_model)
source("C:/Users/Dell/Desktop/ds lab/random.R", echo=TRUE)
library(dplyr)
library(stats)
data <-iris
#inspect base data
View(data)
str(data)
#select numeric data
df<- select(data,c(1:4))
#inspect data
View(df)
#variable selection
var =cor(df)
var
# splitting data
index = sample(2,nrow(df),replace = TRUE,prob = c(.7,.3))
table(index)
train <- df[index==1,]
test<-df[index==2,]
#Building regression model
rm = lm(Petal.Length~Petal.Width+Sepal.Width,df)
#Evaluating model Efficiency
summary(rm)
#Evaluating model Accuracy
PLen_pred = predict(rm,test)
test$PLen_pred=PLen_pred
View(test)
#mean absolute percentage error(MAPE)
error = MAPE(test$PLen_pred,test$Petal.Length)
library(MLmetrics)
install.packages("MLmetrics")
library(MLmetrics)
#mean absolute percentage error(MAPE)
error = MAPE(test$PLen_pred,test$Petal.Length)
error
#Accuracy
acc=1-error
print("Accuracy =",acc)
print(paste("Accuracy =",acc))
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
# Apply the lm() function.
relation <- lm(y~x)
print(summary(relation))
a<- data.frame(170)
pred = predict(relation,a)
a<- data.frame(x=170)
pred = predict(relation,a)
print(pred)
plot(x,y,col="blue",main="height & weight",abline(relation),cex=1.3,pch=16,xlab = "weight in kg",ylab="height in cm")
plot(x,y,col="blue",main="height & weight",abline(relation),xlab = "weight in kg",ylab="height in cm")
plot(x,y,col="blue",main="height & weight",abline(relation),cex=1.3,pch=16,xlab = "weight in kg",ylab="height in cm")
plot(x,y,col="blue",main="height & weight",abline(relation),pch=16,xlab = "weight in kg",ylab="height in cm")
#plot
plot((df$Sepal.Width,df$Sepal.Width),df$Petal.Length,col="green",main="petal_length Vs petal&Sepal widths",pch=16,
#plot
plot(df(2,4),df$Petal.Length,col="green",main="petal_length Vs petal&Sepal widths",pch=16,
xlab="widths",ylab="petal length")
#plot
xdf<- select(df,c(2,4))
plot(xdf,df$Petal.Length,col="green",main="petal_length Vs petal&Sepal widths",pch=16,
xlab="widths",ylab="petal length")
library(caTools)
library(ROCR)
library(dplyr)
data<-mtcars
View(data)
str(data)
data$vs<- as.factor(data$vs)
str(data)
split<- sample.split(data,SplitRatio = 0.7)
train = subset(data,split==TRUE)
test <- subset(data,split==FALSE)
model =glm(vs~ wt+ disp,data=train,family="binomial")
summary(model)
pred <- predict(model,test)
pred
pred<- ifelse(pred>0.5,1,0)
pred
#confusion matrix
cm=table(test$vs,pred)
cm
print(cm)
#Accuracy
err=mean(pred!=test$vs)
print(paste("Accuracy = ",1-err))
#ROC_AUC
prob = prediction(pred,test$vs)
per=performance(prob,measure = 'tpr',x.measure = 'fpr')
auc<-performance(prob,measure = 'auc')
auc
#plotting curve
plot(per)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1).main="ROC curve")
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
source("C:/Users/Dell/Desktop/ds lab/logistic.R", echo=TRUE)
abline(a=0,b=1)
auc<- round(auc,4)
legend(.6,.4,auc,title="AUC",cex=1)
plot(per,col=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
plot(per,colorize=TRUE,pch=16,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
plot(per,colorize=TRUE,col="bule",pch=16,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
plot(per,colorize=TRUE,col="blue",pch=16,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
abline(a=0,b=1)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve",abline(a=0,b=1))
auc<- round(auc,4)
legend(.6,.4,auc,title="AUC",cex=1)
#plotting curve
plot(per)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve",abline(a=0,b=1))
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
abline(a=0,b=1)
legend(.6,.4,auc,title="AUC",cex=1)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
abline(a=0,b=1)
legend(.6,.4,auc,title="AUC",cex=1)
?kmeans
?ROCR
?glm
?apriori
data<- Titanic
View(data)
library(dplyr)
library(arules)
install.packages("arules")
library(arules)
library(arules)
rules<- apriori(data)
data<- read.transactions('titanic.csv',sep = ',',rm.duplicates = TRUE)
data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
View(data)
rules<- apriori(data)
str(data)
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
dataset = read.transactions('Market_Basket_Optimisation.csv',
sep = ', ', rm.duplicates = TRUE)
df<- Market_Basket_Optimisation
library(readr)
Market_Basket_Optimisation <- read_csv("C:\\Users\\Dell\\Desktop\\ds lab\\Market_Basket_Optimisation.csv")
View(Market_Basket_Optimisation)
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
dataset = read.transactions('Market_Basket_Optimisation.csv',
sep = ', ', rm.duplicates = TRUE)
df<- Market_Basket_Optimisation
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
dataset = read.transactions(data,
sep = ', ', rm.duplicates = TRUE)
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
setwd('C:\Users\Dell\Desktop\ds lab')
setwd("C:/Users/Dell/Desktop/ds lab")
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ', ', rm.duplicates = TRUE)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
View(data)
str(data)
rules<- apriori(data)
library(dplyr)
data<-mtrcars
data<-mtcars
str(data)
head(data)
#finding dist. matrix
dist_mtx <- dist(data,method = 'euclidean')
dist_mtx
#fitting hierarchical clustering model
set.seed(240)
hm<- hclust(dist_mtx,method="average")
hm
#plotting dendogram
plot(hm)
#cutting tree by height
abline(h=110,col="green")
#cutting tree by no. of clusters
fit<-cutree(hm,k=3)
fit
table(fit)
rect.hclust(hm,k=3,border="green")
library(caTools)
library(ROCR)
library(dplyr)
data<-mtcars
View(data)
str(data)
data$vs<- as.factor(data$vs)
str(data)
split<- sample.split(data,SplitRatio = 0.7)
train = subset(data,split==TRUE)
test <- subset(data,split==FALSE)
model =glm(vs~ wt+ disp,data=train,family="binomial")
summary(model)
pred <- predict(model,test)
pred
pred<- ifelse(pred>0.5,1,0)
pred
#confusion matrix
cm=table(test$vs,pred)
print(cm)
#Accuracy
err=mean(pred!=test$vs)
print(paste("Accuracy = ",1-err))
#ROC_AUC
prob = prediction(pred,test$vs)
per=performance(prob,measure = 'tpr',x.measure = 'fpr')
auc<-performance(prob,measure = 'auc')
auc<-auc@y.values[[1]]
auc
#plotting curve
plot(per)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
abline(a=0,b=1)
legend(.6,.4,auc,title="AUC",cex=1)
data<-mtcars
str(data)
head(data)
#finding dist. matrix
dist_mtx <- dist(data,method = 'euclidean')
dist_mtx
#fitting hierarchical clustering model
set.seed(240)
hm<- hclust(dist_mtx,method="average")
hm
#plotting dendogram
plot(hm)
#cutting tree by height
abline(h=110,col="green")
#cutting tree by no. of clusters
fit<-cutree(hm,k=3)
fit
table(fit)
rect.hclust(hm,k=3,border="green")
library(dplyr)
data<-mtcars
str(data)
head(data)
#finding dist. matrix
dist_mtx <- dist(data,method = 'euclidean')
dist_mtx
#fitting hierarchical clustering model
set.seed(240)
hm<- hclust(dist_mtx,method="average")
hm
#plotting dendogram
plot(hm)
#choosing no. of clusters
#cutting tree by height
abline(h=110,col="green")
#cutting tree by no. of clusters
fit<-cutree(hm,k=3)
fit
table(fit)
rect.hclust(hm,k=3,border="blue")
library(caTools)
library(ROCR)
library(dplyr)
data<-mtcars
View(data)
str(data)
data$vs<- as.factor(data$vs)
str(data)
split<- sample.split(data,SplitRatio = 0.7)
train = subset(data,split==TRUE)
test <- subset(data,split==FALSE)
model =glm(vs~ wt+ disp,data=train,family="binomial")
summary(model)
pred <- predict(model,test)
pred
pred<- ifelse(pred>0.5,1,0)
pred
#confusion matrix
cm=table(test$vs,pred)
print(cm)
#Accuracy
err=mean(pred!=test$vs)
print(paste("Accuracy = ",1-err))
#ROC_AUC
prob = prediction(pred,test$vs)
per=performance(prob,measure = 'tpr',x.measure = 'fpr')
auc<-performance(prob,measure = 'auc')
auc<-auc@y.values[[1]]
auc
#plotting curve
plot(per)
plot(per,colorize=TRUE,print.cutoffs.at=seq(.1,by=.1),main="ROC curve")
abline(a=0,b=1)
legend(.6,.4,auc,title="AUC",cex=1)
library(dplyr)
library(arules)
install.packages("arulesViz")
library(arulesViz)
df<- Market_Basket_Optimisation
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
setwd("C:/Users/Dell/Desktop/ds lab")
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
View(data)
str(data)
rules<- apriori(data)
?apriori
rules<- apriori(dataset)
inspect(rules)
inspect(rules)
rules
View(dataset)
str(dataset)
rules<- apriori(dataset)
inspect(rules)
rules
rules<- apriori(dataset,parameter = list(support=.004,confidence=0.2))
inspect(rules)
itemFrequencyPlot(dataset,topN=10)
inspect(sort(rules,by='lift')[1:10])
plot(rules,method="graph",measure="confidence",shading="lift")
library(readxl)
data12 <- read_excel("data12.xlsx")
View(data12)
library(dplyr)
str(data12)
data12$ILL<- ifelse(data12$ILL=="Yes",1,0)
str(data12)
data12$Sex<-ifelse(data12$Sex=="Male",1,2)
str(data12)
model= glm(ILL~Age+Sex+Temp,data,family = "binomial")
model= glm(data$ILL~Age+Sex+Temp,data,family = "binomial")
model= glm(data12$ILL~data12$Age+data12$Sex+data12$Temp,data12,family = "binomial")
data12$ILL<-as.factor(data12$ILL)
str(data12)
model= glm(data12$ILL~data12$Age+data12$Sex+data12$Temp,data12,family = "binomial")
model= glm(data12$ILL~data12$Age+data12$Sex+data12$Temp,data=data12,family = "binomial")
c2<-c(65,69,60,75,78,70,56)
c1<- c(171,172,165,181,185,163,145)
df<- data.frame(c1,c2)
df
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
# Apply the lm() function.
relation <- lm(y~x)
print(relation)
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
# Apply the lm() function.
relation <- lm(y~x)
print(summary(relation))
# The predictor vector.
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
# The resposne vector.
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
# Apply the lm() function.
relation <- lm(y~x)
# Find weight of a person with height 170.
a <- data.frame(x = 170)
result <-  predict(relation,a)
print(result)
setwd("C:/Users/Dell/Desktop/ds lab")
library(dplyr)
library(stats)
library(MLmetrics)
data <-iris
#inspect base data
View(data)
str(data)
#select numeric data
df<- select(data,c(1:4)) #select(data,c(1,2,3,4))
#inspect data
View(df)
#variable selection
var =cor(df)
var
# splitting data
index = sample(2,nrow(df),replace = TRUE,prob = c(.7,.3))
table(index)
train <- df[index==1,]
test<-df[index==2,]
#Building regression model
rm = lm(Petal.Length~Petal.Width+Sepal.Width,df)
#Evaluating model Efficiency
summary(rm)
#Evaluating model Accuracy
PLen_pred = predict(rm,test)
test$PLen_pred=PLen_pred
View(test)
#mean absolute percentage error(MAPE)
error = MAPE(test$PLen_pred,test$Petal.Length)
error
#Accuracy
acc=1-error
print(paste("Accuracy =",acc))
?hclust
library(dplyr)
library(arules)
library(arulesViz)
df<- Market_Basket_Optimisation
#data<- read.transactions('Titanic.csv',sep = ',',rm.duplicates = TRUE)
setwd("C:/Users/Dell/Desktop/ds lab")
dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)
View(dataset)
str(dataset)
class(dataset)
inspect(head(dataset,2))
rules<- apriori(dataset,parameter = list(support=.004,confidence=0.2))
inspect(rules)
choco_rule<-apriori(dataset,list(support=0.004,confidence=0.2),list(rhs="chocolate"))
inspect(choco_rule)
rules<- apriori(dataset,parameter = list(support=.01,confidence=0.5))
inspect(rules)
rules<- apriori(dataset,parameter = list(support=.004,confidence=0.2))
inspect(rules)
choco_rule<-apriori(dataset,list(support=0.01,confidence=0.4),list(rhs="chocolate"))
inspect(choco_rule)
choco_rule<-apriori(dataset,list(support=0.008,confidence=0.4),list(rhs="chocolate"))
inspect(choco_rule)
choco_rule<-apriori(dataset,list(support=0.008,confidence=0.2),list(rhs="chocolate"))
inspect(choco_rule)
rules_increase<-apriori(dataset,parameter = list(support=0.02,confidence=0.2))
inspect(rules_increase)
itemFrequencyPlot(dataset,topN=10)
inspect(sort(rules,by='lift')[1:10])
plot(rules,method="graph",measure="confidence",shading="lift")
plot(rules_increase,method="graph",measure="confidence",shading="lift")
